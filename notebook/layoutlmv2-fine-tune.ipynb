{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12316141,"sourceType":"datasetVersion","datasetId":7763055},{"sourceId":12326388,"sourceType":"datasetVersion","datasetId":7769899}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## import library ","metadata":{}},{"cell_type":"code","source":"!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n!pip install mlflow dagshub -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T17:59:01.192094Z","iopub.execute_input":"2025-06-30T17:59:01.192338Z","iopub.status.idle":"2025-06-30T18:01:18.111664Z","shell.execute_reply.started":"2025-06-30T17:59:01.192316Z","shell.execute_reply":"2025-06-30T18:01:18.110968Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport cv2\n\nfrom datasets import (Array2D, Array3D, ClassLabel, Dataset, Features,\n                      Sequence, Value)\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split \nfrom tqdm import tqdm\nfrom transformers import (LayoutLMv2FeatureExtractor,\n                          LayoutLMv2ForSequenceClassification,\n                          LayoutLMv2Processor, LayoutLMv2Tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:04:16.376766Z","iopub.execute_input":"2025-06-30T18:04:16.377076Z","iopub.status.idle":"2025-06-30T18:04:39.652246Z","shell.execute_reply.started":"2025-06-30T18:04:16.377050Z","shell.execute_reply":"2025-06-30T18:04:39.651667Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Params","metadata":{}},{"cell_type":"code","source":"\n\n\ninput_size = 224\nchanel= 3\nepochs = 20\nlr=5e-5\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:05:26.856905Z","iopub.execute_input":"2025-06-30T18:05:26.857485Z","iopub.status.idle":"2025-06-30T18:05:26.861269Z","shell.execute_reply.started":"2025-06-30T18:05:26.857462Z","shell.execute_reply":"2025-06-30T18:05:26.860492Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Ingestion","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2 as cv\nimport random\nfrom sklearn.model_selection import train_test_split\n\ndef get_image_paths(path_to_subset):\n  # Collect all valid image paths\n  paths = []\n  labels=[]\n  for folder in os.listdir(path_to_subset):\n      folder_path = os.path.join(path_to_subset, folder)\n      for image in os.listdir(folder_path):\n          path_to_image = os.path.join(folder_path, image)\n\n          # Check if image is valid\n          img = cv2.imread(path_to_image)\n          if img is not None:\n              paths.append(path_to_image)\n              labels.append(folder)\n\n  data = pd.DataFrame.from_dict({'image_path': paths, 'label': labels})\n  return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:05:29.095486Z","iopub.execute_input":"2025-06-30T18:05:29.096283Z","iopub.status.idle":"2025-06-30T18:05:29.101682Z","shell.execute_reply.started":"2025-06-30T18:05:29.096257Z","shell.execute_reply":"2025-06-30T18:05:29.100804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndf=get_image_paths(\"/kaggle/input/text-document-images/train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:05:31.936757Z","iopub.execute_input":"2025-06-30T18:05:31.937265Z","iopub.status.idle":"2025-06-30T18:05:35.772076Z","shell.execute_reply.started":"2025-06-30T18:05:31.937241Z","shell.execute_reply":"2025-06-30T18:05:35.771458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:05:37.785810Z","iopub.execute_input":"2025-06-30T18:05:37.786099Z","iopub.status.idle":"2025-06-30T18:05:37.806114Z","shell.execute_reply.started":"2025-06-30T18:05:37.786081Z","shell.execute_reply":"2025-06-30T18:05:37.805528Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train-Test SplitÂ¶\n","metadata":{}},{"cell_type":"code","source":"\n\ntrain_df, test_df = train_test_split(df, test_size=0.2)\n\nprint(f\"Train Len:: {len(train_df)}\\tTest Len:: {len(test_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:05:40.591398Z","iopub.execute_input":"2025-06-30T18:05:40.591683Z","iopub.status.idle":"2025-06-30T18:05:40.600773Z","shell.execute_reply.started":"2025-06-30T18:05:40.591662Z","shell.execute_reply":"2025-06-30T18:05:40.600023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_df.label.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:05:43.177052Z","iopub.execute_input":"2025-06-30T18:05:43.177711Z","iopub.status.idle":"2025-06-30T18:05:43.187556Z","shell.execute_reply.started":"2025-06-30T18:05:43.177692Z","shell.execute_reply":"2025-06-30T18:05:43.186882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntest_df.label.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:05:46.461674Z","iopub.execute_input":"2025-06-30T18:05:46.462349Z","iopub.status.idle":"2025-06-30T18:05:46.468329Z","shell.execute_reply.started":"2025-06-30T18:05:46.462326Z","shell.execute_reply":"2025-06-30T18:05:46.467643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ntrain_dataset = Dataset.from_pandas(train_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:05:49.591860Z","iopub.execute_input":"2025-06-30T18:05:49.592127Z","iopub.status.idle":"2025-06-30T18:05:49.613797Z","shell.execute_reply.started":"2025-06-30T18:05:49.592109Z","shell.execute_reply":"2025-06-30T18:05:49.613299Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tokenizer","metadata":{}},{"cell_type":"code","source":"\n\nlabels=list(set(df[\"label\"]))\nlabels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:05:51.927573Z","iopub.execute_input":"2025-06-30T18:05:51.927881Z","iopub.status.idle":"2025-06-30T18:05:51.932989Z","shell.execute_reply.started":"2025-06-30T18:05:51.927824Z","shell.execute_reply":"2025-06-30T18:05:51.932413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nid2label = {v: k for v, k in enumerate(labels)}\nlabel2id = {k: v for v, k in enumerate(labels)}\nprint(label2id)\nprint(id2label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:05:53.827599Z","iopub.execute_input":"2025-06-30T18:05:53.827991Z","iopub.status.idle":"2025-06-30T18:05:53.832524Z","shell.execute_reply.started":"2025-06-30T18:05:53.827962Z","shell.execute_reply":"2025-06-30T18:05:53.831730Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nfeature_extractor = LayoutLMv2FeatureExtractor()\ntokenizer = LayoutLMv2Tokenizer.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\nprocessor = LayoutLMv2Processor(feature_extractor, tokenizer)\n\n\n# we need to define custom features\nfeatures = Features({\n    'image': Array3D(dtype=\"int64\", shape=(chanel, input_size, input_size)),\n    'input_ids': Sequence(feature=Value(dtype='int64')),\n    'attention_mask': Sequence(Value(dtype='int64')),\n    'token_type_ids': Sequence(Value(dtype='int64')),\n    'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n    'labels': ClassLabel(num_classes=len(labels), names=labels),\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:05:56.032331Z","iopub.execute_input":"2025-06-30T18:05:56.033030Z","iopub.status.idle":"2025-06-30T18:05:57.900282Z","shell.execute_reply.started":"2025-06-30T18:05:56.033005Z","shell.execute_reply":"2025-06-30T18:05:57.899723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef preprocess_data(examples):\n    # take a batch of images\n    images = [Image.open(path).convert(\"RGB\")\n              for path in examples['image_path']]\n    encoded_inputs = processor(images, padding=\"max_length\", truncation=True)\n\n    # add labels\n    encoded_inputs[\"labels\"] = [label2id[label] for label in examples[\"label\"]]\n\n    return encoded_inputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:05:59.485940Z","iopub.execute_input":"2025-06-30T18:05:59.486214Z","iopub.status.idle":"2025-06-30T18:05:59.490663Z","shell.execute_reply.started":"2025-06-30T18:05:59.486196Z","shell.execute_reply":"2025-06-30T18:05:59.489961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nprint(\"\\nEncoding Dataset\")\ntrain_encoded_data = train_dataset.map(preprocess_data, remove_columns=train_dataset.column_names, \n                                       features=features, batched=True, batch_size=2)\n\ntrain_encoded_data.set_format(type=\"torch\", device=device)\n\n\ntest_encoded_data = test_dataset.map(preprocess_data, remove_columns=test_dataset.column_names, \n                                     features=features, batched=True, batch_size=2)\n\ntest_encoded_data.set_format(type=\"torch\", device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:06:03.296526Z","iopub.execute_input":"2025-06-30T18:06:03.297175Z","iopub.status.idle":"2025-06-30T18:16:01.403178Z","shell.execute_reply.started":"2025-06-30T18:06:03.297143Z","shell.execute_reply":"2025-06-30T18:16:01.402415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# data loaders\ntrain_dataloader = torch.utils.data.DataLoader(train_encoded_data, batch_size=8, shuffle=True)\ntest_dataloader = torch.utils.data.DataLoader(test_encoded_data, batch_size=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:23:14.771607Z","iopub.execute_input":"2025-06-30T18:23:14.772358Z","iopub.status.idle":"2025-06-30T18:23:14.776495Z","shell.execute_reply.started":"2025-06-30T18:23:14.772333Z","shell.execute_reply":"2025-06-30T18:23:14.775796Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Show sample ","metadata":{}},{"cell_type":"code","source":"\ndf['image_path'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T17:09:12.136999Z","iopub.execute_input":"2025-06-30T17:09:12.137607Z","iopub.status.idle":"2025-06-30T17:09:12.142545Z","shell.execute_reply.started":"2025-06-30T17:09:12.137584Z","shell.execute_reply":"2025-06-30T17:09:12.141971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image, ImageDraw, ImageFont\n\nimage = Image.open(df['image_path'][10])\nimage = image.convert(\"RGB\")\nimage","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T17:09:13.917806Z","iopub.execute_input":"2025-06-30T17:09:13.918102Z","iopub.status.idle":"2025-06-30T17:09:14.298727Z","shell.execute_reply.started":"2025-06-30T17:09:13.918078Z","shell.execute_reply":"2025-06-30T17:09:14.297825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoded_inputs = processor(image, return_tensors=\"pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T17:09:23.675232Z","iopub.execute_input":"2025-06-30T17:09:23.676027Z","iopub.status.idle":"2025-06-30T17:09:26.121623Z","shell.execute_reply.started":"2025-06-30T17:09:23.676000Z","shell.execute_reply":"2025-06-30T17:09:26.120823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfor k,v in encoded_inputs.items():\n  print(k, v.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T17:09:26.717357Z","iopub.execute_input":"2025-06-30T17:09:26.717697Z","iopub.status.idle":"2025-06-30T17:09:26.723096Z","shell.execute_reply.started":"2025-06-30T17:09:26.717674Z","shell.execute_reply":"2025-06-30T17:09:26.721970Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprocessor.tokenizer.decode(encoded_inputs.input_ids.squeeze().tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T17:09:33.903195Z","iopub.execute_input":"2025-06-30T17:09:33.903618Z","iopub.status.idle":"2025-06-30T17:09:33.910755Z","shell.execute_reply.started":"2025-06-30T17:09:33.903589Z","shell.execute_reply":"2025-06-30T17:09:33.910170Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modle training","metadata":{}},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"\nmodel = LayoutLMv2ForSequenceClassification.from_pretrained(\"microsoft/layoutlmv2-base-uncased\", \n                                                            num_labels=len(labels))\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:23:21.446050Z","iopub.execute_input":"2025-06-30T18:23:21.446343Z","iopub.status.idle":"2025-06-30T18:23:45.513875Z","shell.execute_reply.started":"2025-06-30T18:23:21.446322Z","shell.execute_reply":"2025-06-30T18:23:45.513018Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## mlflow setup","metadata":{}},{"cell_type":"code","source":"import dagshub\nimport mlflow\n\ndagshub.init(repo_owner='kaushigihanml', repo_name='document_classification', mlflow=True)\nmlflow.set_tracking_uri(\"https://dagshub.com/kaushigihanml/document_classification.mlflow\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:23:51.577212Z","iopub.execute_input":"2025-06-30T18:23:51.577576Z","iopub.status.idle":"2025-06-30T18:24:03.082946Z","shell.execute_reply.started":"2025-06-30T18:23:51.577547Z","shell.execute_reply":"2025-06-30T18:24:03.071597Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training ","metadata":{}},{"cell_type":"code","source":"\nclass_names = list(label2id.keys())\nclass_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:24:08.548504Z","iopub.execute_input":"2025-06-30T18:24:08.548783Z","iopub.status.idle":"2025-06-30T18:24:08.553726Z","shell.execute_reply.started":"2025-06-30T18:24:08.548761Z","shell.execute_reply":"2025-06-30T18:24:08.553067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score, classification_report\nimport numpy as np\nimport mlflow\n\n\ndef eval_prediction(test_dataloader,model):\n\n    #model.eval()\n    predict_label=[]\n    true_label=[]\n    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n        with torch.no_grad():\n            input_ids = batch['input_ids'].to(device)\n            bbox = batch['bbox'].to(device)\n            image = batch['image'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            labels = batch['labels'].to(device)\n    \n            # forward pass\n            outputs = model(input_ids=input_ids, bbox=bbox, image=image, attention_mask=attention_mask, \n                            token_type_ids=token_type_ids, labels=labels)\n            predictions = outputs.logits.argmax(-1)\n            predict_label.extend(predictions)\n            true_label.extend(labels)\n    \n            \n    int_pred_list = [t.item() for t in predict_label]\n    int_real_list = [t.item() for t in true_label]\n\n    return int_pred_list,int_real_list\n\n\n\ndef evaluate(model,test_dataloader):\n    # Assuming 'true_labels' are the true labels and 'predicted_labels' are the predicted labels\n    predicted_labels,true_labels=eval_prediction(test_dataloader,model)\n\n    # Define class labels\n    class_names = list(label2id.keys())\n    \n    # Create the confusion matrix\n    cm = confusion_matrix(true_labels, predicted_labels)\n    \n    # Create a heatmap of the confusion matrix\n    plt.figure(figsize=(8, 6))\n    sns.set(font_scale=1.2)\n    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=class_names, yticklabels=class_names)\n    \n    plt.title(\"Confusion Matrix\")\n    plt.ylabel(\"True Label\")\n    plt.xlabel(\"Predicted Label\")\n    plt.savefig(\"confusion_matrix.png\", dpi=300, bbox_inches=\"tight\")\n    mlflow.log_artifact(\"confusion_matrix.png\")\n    plt.close()\n    \n    \n    # Classification report\n    report = classification_report(\n        true_labels,predicted_labels, target_names=class_names, output_dict=True\n    )\n    #print(report)\n    \n    # Log per-class metrics\n    for class_name in class_names:\n        if class_name in report:\n            mlflow.log_metrics(\n                {\n                    f\"{class_name}_precision\": report[class_name][\"precision\"],\n                    f\"{class_name}_recall\": report[class_name][\"recall\"],\n                    f\"{class_name}_f1\": report[class_name][\"f1-score\"],\n                }\n            )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:24:10.837028Z","iopub.execute_input":"2025-06-30T18:24:10.837299Z","iopub.status.idle":"2025-06-30T18:24:11.502496Z","shell.execute_reply.started":"2025-06-30T18:24:10.837280Z","shell.execute_reply":"2025-06-30T18:24:11.501991Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" eval_prediction(test_dataloader,model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:24:22.358069Z","iopub.execute_input":"2025-06-30T18:24:22.358719Z","iopub.status.idle":"2025-06-30T18:24:28.430143Z","shell.execute_reply.started":"2025-06-30T18:24:22.358694Z","shell.execute_reply":"2025-06-30T18:24:28.429369Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"import mlflow\nfrom torch.optim import AdamW\nfrom tqdm.notebook import tqdm\n\n# Start MLflow run\nmlflow.set_experiment(\"Layout_model\")\nmlflow.start_run(run_name=\"layoutlmv2\",nested=True)\n\n# Log hyperparameters\nmlflow.log_params({\n    \"learning_rate\": 5e-5,\n    \"num_train_epochs\": epochs,\n    \"optimizer\": \"AdamW\"\n})\nwith open(\"label2id.txt\", \"w\") as f:\n    for key, value in label2id.items():\n        f.write(f\"{key}: {value}\\n\")\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\nglobal_step = 0\n\nmodel.train()\nfor epoch in range(epochs):\n    print(\"Epoch:\", epoch)\n    running_loss = 0.0\n    correct = 0\n    total_samples = 0\n\n    for batch in tqdm(train_dataloader):\n        outputs = model(**batch)\n        loss = outputs.loss\n\n        running_loss += loss.item()\n        predictions = outputs.logits.argmax(-1)\n        correct += (predictions == batch['labels']).float().sum()\n        total_samples += batch['labels'].size(0)\n\n        # Backward pass and optimization step\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        global_step += 1\n\n        # Optionally log batch-level loss\n        if global_step % 100 == 0:\n            mlflow.log_metric(\"batch_loss\", loss.item(), step=global_step)\n\n    epoch_loss = running_loss / total_samples\n    accuracy = 100 * correct / total_samples\n\n    print(f\"Loss: {epoch_loss:.4f}\")\n    print(f\"Training accuracy: {accuracy.item():.2f}%\")\n\n    # Log epoch metrics\n    mlflow.log_metric(\"epoch_loss\", epoch_loss, step=epoch)\n    mlflow.log_metric(\"epoch_accuracy\", accuracy.item(), step=epoch)\n\n# Optionally log the final model\n#mlflow.pytorch.log_model(model, \"model\")\n#run evaluatorS\nevaluate(model=model,test_dataloader=test_dataloader)\nmodel.save_pretrained(\"model.pth\")\nmlflow.log_artifact(\"/kaggle/working/model.pth\")\nmlflow.log_artifact(\"/kaggle/working/label2id.txt\")\nmlflow.end_run()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:24:43.691634Z","iopub.execute_input":"2025-06-30T18:24:43.692371Z","iopub.status.idle":"2025-06-30T18:26:06.508758Z","shell.execute_reply.started":"2025-06-30T18:24:43.692348Z","shell.execute_reply":"2025-06-30T18:26:06.508212Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"\nfrom PIL import Image, ImageDraw, ImageFont\nfrom transformers import LayoutLMv2ForSequenceClassification\nfrom transformers import (LayoutLMv2FeatureExtractor,\n                          LayoutLMv2ForSequenceClassification,\n                          LayoutLMv2Processor, LayoutLMv2Tokenizer)\n\n\ntry:\n    feature_extractor = LayoutLMv2FeatureExtractor()\n    tokenizer = LayoutLMv2Tokenizer.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n    processor = LayoutLMv2Processor(feature_extractor, tokenizer)\n    load_model = LayoutLMv2ForSequenceClassification.from_pretrained(\"/kaggle/working/model.pth\")\n    model.to(device)\nexcept Exception as e:\n    raise e\n\n\ndef layout_model_prediction(img_path):\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    image = Image.open(img_path)\n    image = image.convert(\"RGB\")\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    # prepare image for the model\n    encoded_inputs = processor(\n    image,\n    return_tensors=\"pt\",\n    truncation=True,\n    padding=\"max_length\",\n    max_length=512)\n \n    # make sure all keys of encoded_inputs are on the same device as the model\n    for k,v in encoded_inputs.items():\n      encoded_inputs[k] = v.to(model.device)\n        \n    load_model.to(device)\n    # forward pass\n    outputs = load_model(**encoded_inputs)\n    logits = outputs.logits\n\n    predicted_class_idx = logits.argmax(-1).item()\n    print(\"Predicted class:\", id2label[predicted_class_idx])\n\n    return id2label[predicted_class_idx]\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:30:45.643230Z","iopub.execute_input":"2025-06-30T18:30:45.643956Z","iopub.status.idle":"2025-06-30T18:30:46.729255Z","shell.execute_reply.started":"2025-06-30T18:30:45.643936Z","shell.execute_reply":"2025-06-30T18:30:46.728683Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\nlayout_model_prediction(df['image_path'][25])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T18:33:29.136776Z","iopub.execute_input":"2025-06-30T18:33:29.137065Z","iopub.status.idle":"2025-06-30T18:33:31.011267Z","shell.execute_reply.started":"2025-06-30T18:33:29.137046Z","shell.execute_reply":"2025-06-30T18:33:31.010757Z"}},"outputs":[],"execution_count":null}]}