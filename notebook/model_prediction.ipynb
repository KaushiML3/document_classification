{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["0GUmgdiqLSdT","H780lemBgM0g"],"mount_file_id":"1scAZ-AsNfBzptPpOXJmoJYH0esORHzcW","authorship_tag":"ABX9TyMVFY/xYZuHBKQTBTXyx0lF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# VGG16 model"],"metadata":{"id":"0GUmgdiqLSdT"}},{"cell_type":"code","source":["import cv2\n","import keras\n","from pathlib import Path\n","import tensorflow as tf\n","import joblib\n","from sklearn.preprocessing import MultiLabelBinarizer\n","import numpy as np\n","\n","\n","def __preprocess_image(path):\n","    img = cv2.imread(path)\n","    if img is not None:\n","      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","      img = cv2.resize(img, (224,224))  # width, height\n","      img = img.astype(\"float32\") / 255.0\n","      #img = np.reshape(img, self.image_size)  # (height, width, channels)\n","      return img\n","    else:\n","      print(\"Image not found\")\n","      return None\n","\n","\n","def mlb_load(file_path:Path)->MultiLabelBinarizer:\n","\n","    try:\n","        # Assuming you run this notebook from the root of your project directory\n","        mlb = joblib.load(file_path)\n","\n","    except FileNotFoundError:\n","        print(\"Error: 'artifacts/model/vgg_model/mlb.joblib' not found.\")\n","        print(\"Please make sure the path is correct. Using a placeholder binarizer.\")\n","        # As a placeholder, let's create a dummy mlb if the file is not found.\n","        mlb = MultiLabelBinarizer()\n","        # This should be the set of your actual labels.\n","        mlb.fit([['advertisement', 'email', 'form', 'invoice', 'note']])\n","\n","    return mlb\n","\n","\n","def load_vgg_model() -> tuple[tf.keras.Model, MultiLabelBinarizer]:\n","  try:\n","\n","      mlb_file_path=Path(\"/content/drive/MyDrive/Work_space/Project/document_classification/artifacts/model/vgg_model/mlb.joblib\")\n","      model_file_path=Path(\"/content/drive/MyDrive/Work_space/Project/document_classification/artifacts/model/vgg_model/model.keras\")\n","      # Select model\n","      # Load the entire model\n","      mlb=mlb_load(mlb_file_path)\n","      model=tf.keras.models.load_model(model_file_path) # Corrected to use tf.keras.models.load_model\n","      return model,mlb\n","\n","  except Exception as e:\n","      raise e\n","\n","\n","try:\n","  model,mlb=load_vgg_model()\n","except Exception as e:\n","  print(e)\n","\n","def vgg_model_prediction(image_path):\n","  # Check if image is valid\n","  image=__preprocess_image(image_path)\n","  if image is not None:\n","      # Add batch dimension to the image\n","      image = np.expand_dims(image, axis=0)\n","      prd = model.predict(image)\n","      # Convert the prediction to a binary indicator format\n","      pred_id = np.argmax(prd, axis=1)\n","      #print(pred_id)\n","      # Create a zero array with the shape (1, number of classes)\n","      binary_prediction = np.zeros((1, len(mlb.classes_)))\n","      #print(binary_prediction)\n","      # Set the index of the predicted class to 1\n","      binary_prediction[0, pred_id] = 1\n","      #print(binary_prediction)\n","      predicted_labels = mlb.inverse_transform(binary_prediction)\n","      #print(f\"Predicted labels: {predicted_labels}\")\n","      return {\"status\":1,\"message\":predicted_labels[0][0]}\n","  else:\n","      return {\"status\":0, \"message\": \"Image not processed.\"}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AJ_EMP9lLVzE","executionInfo":{"status":"ok","timestamp":1751277575534,"user_tz":-330,"elapsed":2195,"user":{"displayName":"Kaushi Gihan ML","userId":"11214181140146971518"}},"outputId":"f60ce686-4f56-4708-9a1c-e50a09c5f864"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MultiLabelBinarizer from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["vgg_model_prediction(\"/content/38.jpg\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"psO4j4XDOPEg","executionInfo":{"status":"ok","timestamp":1751277583849,"user_tz":-330,"elapsed":719,"user":{"displayName":"Kaushi Gihan ML","userId":"11214181140146971518"}},"outputId":"824a5371-428c-4afb-a693-0356825f9091"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["{'status': 1, 'message': 'invoice'}"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["## Production grade"],"metadata":{"id":"KKypK6MRpJEi"}},{"cell_type":"code","metadata":{"id":"c174c15e","executionInfo":{"status":"ok","timestamp":1751283718220,"user_tz":-330,"elapsed":17,"user":{"displayName":"Kaushi Gihan ML","userId":"11214181140146971518"}}},"source":["import logging\n","import joblib\n","import tensorflow as tf\n","from pathlib import Path\n","from sklearn.preprocessing import MultiLabelBinarizer\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","def load_vgg_artifacts(model_path: Path, mlb_path: Path) -> tuple[tf.keras.Model, MultiLabelBinarizer]:\n","    \"\"\"\n","    Loads the VGG model and the MultiLabelBinarizer from specified paths.\n","\n","    Args:\n","        model_path: Path to the VGG model file (.keras).\n","        mlb_path: Path to the MultiLabelBinarizer file (.joblib).\n","\n","    Returns:\n","        A tuple containing the loaded Keras model and MultiLabelBinarizer object.\n","\n","    Raises:\n","        FileNotFoundError: If either the model file or the MLB file is not found.\n","        Exception: If any other error occurs during loading.\n","    \"\"\"\n","    model = None\n","    mlb = None\n","    try:\n","        logging.info(f\"Attempting to load VGG model from {model_path}\")\n","        model = tf.keras.models.load_model(model_path)\n","        logging.info(\"VGG model loaded successfully.\")\n","    except FileNotFoundError:\n","        logging.error(f\"Error: VGG model file not found at {model_path}\")\n","        raise\n","    except Exception as e:\n","        logging.error(f\"An error occurred while loading the VGG model: {e}\")\n","        raise\n","\n","    try:\n","        logging.info(f\"Attempting to load MultiLabelBinarizer from {mlb_path}\")\n","        mlb = joblib.load(mlb_path)\n","        logging.info(\"MultiLabelBinarizer loaded successfully.\")\n","    except FileNotFoundError:\n","        logging.error(f\"Error: MultiLabelBinarizer file not found at {mlb_path}\")\n","        raise\n","    except Exception as e:\n","        logging.error(f\"An error occurred while loading the MultiLabelBinarizer: {e}\")\n","        raise\n","\n","    logging.info(\"Both VGG model and MultiLabelBinarizer loaded successfully.\")\n","    return model, mlb\n","\n"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"id":"509c0716","executionInfo":{"status":"ok","timestamp":1751283721709,"user_tz":-330,"elapsed":4,"user":{"displayName":"Kaushi Gihan ML","userId":"11214181140146971518"}}},"source":["import cv2\n","import numpy as np\n","import logging\n","from pathlib import Path\n","\n","# Configure logging (if not already configured in a previous cell)\n","# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","\n","def preprocess_image(image_path: Path, target_size: tuple[int, int] = (224, 224)) -> np.ndarray | None:\n","    \"\"\"\n","    Preprocesses an image for VGG model prediction.\n","\n","    Loads an image from the specified path, converts it to RGB, resizes it,\n","    and normalizes pixel values. Includes robust error handling and logging\n","    at each step.\n","\n","    Args:\n","        image_path: Path to the image file.\n","        target_size: A tuple (width, height) specifying the desired output size.\n","\n","    Returns:\n","        A preprocessed NumPy array representing the image with pixel values\n","        scaled between 0 and 1, or None if an error occurred during processing.\n","    \"\"\"\n","    try:\n","        logging.info(f\"Attempting to load image from {image_path}\")\n","        img = cv2.imread(str(image_path)) # cv2.imread expects a string or numpy array\n","\n","        if img is None:\n","            logging.error(f\"Error: Could not load image from {image_path}. cv2.imread returned None.\")\n","            return None\n","        logging.info(\"Image loaded successfully.\")\n","\n","        logging.info(\"Attempting to convert image to RGB.\")\n","        # Check if the image is already in a format that doesn't need BGR to RGB conversion\n","        # cv2.imread loads in BGR format by default for color images.\n","        # If the image is grayscale, it might be loaded as such.\n","        # We want RGB for consistency with models trained on RGB data.\n","        if len(img.shape) == 3 and img.shape[2] == 3: # Check if it's a color image (likely BGR)\n","            try:\n","                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","                logging.info(\"Image converted to RGB successfully.\")\n","            except cv2.error as e:\n","                logging.error(f\"Error during BGR to RGB conversion for image {image_path}: {e}\")\n","                return None\n","        elif len(img.shape) == 2: # Grayscale image\n","             try:\n","                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n","                logging.info(\"Grayscale image converted to RGB successfully.\")\n","             except cv2.error as e:\n","                logging.error(f\"Error during Grayscale to RGB conversion for image {image_path}: {e}\")\n","                return None\n","        else:\n","             logging.warning(f\"Unexpected image format for {image_path}. Attempting to proceed.\")\n","             # If it's not a standard color or grayscale, we might proceed but log a warning.\n","             # Depending on requirements, you might want to return None here.\n","\n","\n","        logging.info(f\"Attempting to resize image to {target_size}.\")\n","        try:\n","            img = cv2.resize(img, target_size)\n","            if img is None or img.size == 0:\n","                 logging.error(f\"Error: cv2.resize returned None or empty array for image {image_path}.\")\n","                 return None\n","            logging.info(\"Image resized successfully.\")\n","        except cv2.error as e:\n","            logging.error(f\"Error during image resizing for image {image_path} to size {target_size}: {e}\")\n","            return None\n","\n","\n","        logging.info(\"Attempting to normalize pixel values.\")\n","        try:\n","            # Ensure the image is the correct dtype before division\n","            img = img.astype(\"float32\") / 255.0\n","            if img is None or img.size == 0 or np.max(img) > 1.0 or np.min(img) < 0.0:\n","                 logging.error(f\"Error: Image normalization failed or resulted in unexpected values for image {image_path}.\")\n","                 return None\n","            logging.info(\"Pixel values normalized successfully.\")\n","        except Exception as e:\n","            logging.error(f\"Error during pixel normalization for image {image_path}: {e}\")\n","            return None\n","\n","        logging.info(f\"Image preprocessing completed successfully for {image_path}.\")\n","        return img\n","\n","    except Exception as e:\n","        logging.error(f\"An unexpected error occurred during image preprocessing for {image_path}: {e}\")\n","        return None\n"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cab3148","executionInfo":{"status":"ok","timestamp":1751283725611,"user_tz":-330,"elapsed":56,"user":{"displayName":"Kaushi Gihan ML","userId":"11214181140146971518"}},"outputId":"b02d32e4-a6a8-4438-e36f-76fda7ae6191"},"source":["import cv2\n","import keras\n","from pathlib import Path\n","import tensorflow as tf\n","import joblib\n","from sklearn.preprocessing import MultiLabelBinarizer\n","import numpy as np\n","import logging\n","from typing import Optional, Tuple, List\n","\n","# Configure logging (if not already configured)\n","if not logging.getLogger('').handlers:\n","    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","    logging.info(\"Logging configured with basicConfig.\")\n","else:\n","    logging.info(\"Logging already configured.\")\n","\n","class VGGDocumentClassifier:\n","    \"\"\"\n","    A class for classifying documents using a VGG16 model.\n","\n","    This class encapsulates the loading of the VGG16 model and its associated\n","    MultiLabelBinarizer, provides a method to preprocess input images, and\n","    performs document classification predictions.\n","    \"\"\"\n","\n","    def __init__(self, model_path: Path, mlb_path: Path, target_size: Tuple[int, int] = (224, 224)) -> None:\n","        \"\"\"\n","        Initializes the VGGDocumentClassifier by loading the model and MLB.\n","\n","        Args:\n","            model_path: Path to the VGG model file (.keras).\n","            mlb_path: Path to the MultiLabelBinarizer file (.joblib).\n","            target_size: The target size (width, height) for image preprocessing.\n","                         Defaults to (224, 224).\n","\n","        Raises:\n","            FileNotFoundError: If either the model file or the MLB file is not found.\n","            Exception: If any other error occurs during loading.\n","        \"\"\"\n","        logging.info(\"Initializing VGGDocumentClassifier.\")\n","        self.model: Optional[tf.keras.Model] = None\n","        self.mlb: Optional[MultiLabelBinarizer] = None\n","        self.target_size: Tuple[int, int] = target_size\n","\n","        try:\n","            self._load_artifacts(model_path, mlb_path)\n","            if self.model and self.mlb:\n","                logging.info(\"VGGDocumentClassifier initialized successfully.\")\n","            else:\n","                logging.critical(\"VGGDocumentClassifier failed to fully initialize due to artifact loading errors.\")\n","                raise RuntimeError(\"Failed to load all required artifacts for VGGDocumentClassifier.\")\n","        except Exception as e:\n","            logging.critical(f\"Failed to initialize VGGDocumentClassifier: {e}\", exc_info=True)\n","            raise # Re-raise the exception after logging\n","\n","\n","    def _load_artifacts(self, model_path: Path, mlb_path: Path) -> None:\n","        \"\"\"\n","        Loads the VGG model and MultiLabelBinarizer with error handling and logging.\n","\n","        Args:\n","            model_path: Path to the VGG model file (.keras).\n","            mlb_path: Path to the MultiLabelBinarizer file (.joblib).\n","\n","        Raises:\n","            FileNotFoundError: If either the model file or the MLB file is not found.\n","            Exception: If any other unexpected error occurs during loading.\n","        \"\"\"\n","        logging.info(\"Starting artifact loading.\")\n","        model_loaded: bool = False\n","        mlb_loaded: bool = False\n","\n","        # Load Model\n","        try:\n","            logging.info(f\"Attempting to load VGG model from {model_path}\")\n","            self.model = tf.keras.models.load_model(model_path)\n","            logging.info(\"VGG model loaded successfully.\")\n","            model_loaded = True\n","        except FileNotFoundError:\n","            logging.critical(f\"Critical Error: VGG model file not found at {model_path}\", exc_info=True)\n","            raise # Re-raise to indicate a critical initialization failure\n","        except Exception as e:\n","            logging.critical(f\"Critical Error: An unexpected error occurred while loading the VGG model from {model_path}: {e}\", exc_info=True)\n","            raise # Re-raise to indicate a critical initialization failure\n","\n","        # Load MLB\n","        try:\n","            logging.info(f\"Attempting to load MultiLabelBinarizer from {mlb_path}\")\n","            self.mlb = joblib.load(mlb_path)\n","            logging.info(\"MultiLabelBinarizer loaded successfully.\")\n","            mlb_loaded = True\n","        except FileNotFoundError:\n","            logging.critical(f\"Critical Error: MultiLabelBinarizer file not found at {mlb_path}\", exc_info=True)\n","            raise # Re-raise to indicate a critical initialization failure\n","        except Exception as e:\n","            logging.critical(f\"Critical Error: An unexpected error occurred while loading the MultiLabelBinarizer from {mlb_path}: {e}\", exc_info=True)\n","            raise # Re-raise to indicate a critical initialization failure\n","\n","        if model_loaded and mlb_loaded:\n","             logging.info(\"All required VGG artifacts loaded successfully.\")\n","        else:\n","            logging.error(\"One or more required VGG artifacts failed to load during _load_artifacts.\")\n","\n","\n","    def preprocess_image(self, image_path: Path) -> Optional[np.ndarray]:\n","        \"\"\"\n","        Preprocesses an image for VGG model prediction.\n","\n","        Loads an image from the specified path, converts it to RGB, resizes it,\n","        and normalizes pixel values. Includes robust error handling and logging\n","        at each step.\n","\n","        Args:\n","            image_path: Path to the image file.\n","\n","        Returns:\n","            A preprocessed NumPy array representing the image with pixel values\n","            scaled between 0 and 1, or None if an error occurred during processing.\n","        \"\"\"\n","        try:\n","            logging.info(f\"Attempting to load image from {image_path}\")\n","            img = cv2.imread(str(image_path)) # cv2.imread expects a string or numpy array\n","\n","            if img is None:\n","                logging.error(f\"Error: Could not load image from {image_path}. cv2.imread returned None.\")\n","                return None\n","            logging.info(\"Image loaded successfully.\")\n","\n","            logging.info(\"Attempting to convert image to RGB.\")\n","            if len(img.shape) == 3 and img.shape[2] == 3: # Check if it's a color image (likely BGR)\n","                try:\n","                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","                    logging.info(\"Image converted to RGB successfully.\")\n","                except cv2.error as e:\n","                    logging.error(f\"Error during BGR to RGB conversion for image {image_path}: {e}\")\n","                    return None\n","            elif len(img.shape) == 2: # Grayscale image\n","                 try:\n","                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n","                    logging.info(\"Grayscale image converted to RGB successfully.\")\n","                 except cv2.error as e:\n","                    logging.error(f\"Error during Grayscale to RGB conversion for image {image_path}: {e}\")\n","                    return None\n","            else:\n","                 logging.warning(f\"Unexpected image format for {image_path}. Attempting to proceed.\")\n","\n","\n","            logging.info(f\"Attempting to resize image to {self.target_size}.\")\n","            try:\n","                img = cv2.resize(img, self.target_size)\n","                if img is None or img.size == 0:\n","                     logging.error(f\"Error: cv2.resize returned None or empty array for image {image_path}.\")\n","                     return None\n","                logging.info(\"Image resized successfully.\")\n","            except cv2.error as e:\n","                logging.error(f\"Error during image resizing for image {image_path} to size {self.target_size}: {e}\")\n","                return None\n","\n","\n","            logging.info(\"Attempting to normalize pixel values.\")\n","            try:\n","                img = img.astype(\"float32\") / 255.0\n","                if img is None or img.size == 0 or np.max(img) > 1.0 or np.min(img) < 0.0:\n","                     logging.error(f\"Error: Image normalization failed or resulted in unexpected values for image {image_path}.\")\n","                     return None\n","                logging.info(\"Pixel values normalized successfully.\")\n","            except Exception as e:\n","                logging.error(f\"Error during pixel normalization for image {image_path}: {e}\")\n","                return None\n","\n","            logging.info(f\"Image preprocessing completed successfully for {image_path}.\")\n","            return img\n","\n","        except Exception as e:\n","            logging.error(f\"An unexpected error occurred during image preprocessing for {image_path}: {e}\")\n","            return None\n","\n","\n","    def predict(self, image_path: Path) -> Optional[List[str]]:\n","        \"\"\"\n","        Predicts the class labels for a given image using the loaded VGG model.\n","\n","        The process involves loading and preprocessing the image, performing\n","        inference with the model, and converting the prediction to class labels\n","        using the MultiLabelBinarizer.\n","\n","        Args:\n","            image_path: Path to the image file to classify.\n","\n","        Returns:\n","            A list of predicted class labels (strings) if the prediction process\n","            is successful. Returns None if any critical step (image loading,\n","            preprocessing, model inference, or inverse transform) fails.\n","            Returns an empty list if the prediction process is successful but\n","            no labels are predicted.\n","        \"\"\"\n","        logging.info(f\"Starting prediction process for image: {image_path}.\")\n","\n","        if self.model is None or self.mlb is None:\n","            logging.error(\"Model or MultiLabelBinarizer not loaded. Cannot perform prediction.\")\n","            return None\n","\n","        # Preprocess image\n","        image = self.preprocess_image(image_path)\n","        if image is None:\n","            logging.error(f\"Image preprocessing failed for {image_path}. Cannot perform prediction.\")\n","            return None\n","\n","        try:\n","            logging.info(f\"Performing model inference for {image_path}.\")\n","            # Add batch dimension to the image\n","            image = np.expand_dims(image, axis=0)\n","            prd = self.model.predict(image)\n","            logging.info(f\"Model inference completed for {image_path}. Prediction shape: {prd.shape}\")\n","        except Exception as e:\n","            logging.error(f\"An error occurred during model inference for {image_path}: {e}\", exc_info=True)\n","            return None\n","\n","\n","        # Convert the prediction to a binary indicator format and get labels\n","        try:\n","            logging.info(f\"Converting prediction to labels for {image_path}.\")\n","            # Assuming multi-class classification for now, taking the argmax\n","            # If it's multi-label, you'd apply a sigmoid and thresholding here\n","            pred_id = np.argmax(prd, axis=1)\n","\n","            # Create a zero array with the shape (1, number of classes)\n","            binary_prediction = np.zeros((1, len(self.mlb.classes_)))\n","            # Set the index of the predicted class to 1\n","            binary_prediction[0, pred_id] = 1\n","\n","\n","            predicted_labels_tuple_list: List[Tuple[str, ...]] = self.mlb.inverse_transform(binary_prediction)\n","            logging.info(f\"Prediction processed for {image_path}. Predicted labels (raw tuple list): {predicted_labels_tuple_list}\")\n","\n","            if predicted_labels_tuple_list and len(predicted_labels_tuple_list) > 0:\n","                 final_labels: List[str] = list(predicted_labels_tuple_list[0])\n","                 logging.info(f\"Final predicted labels for {image_path}: {final_labels}\")\n","                 return final_labels\n","            else:\n","                 logging.warning(f\"MLB inverse_transform returned an empty list for {image_path}. No labels predicted.\")\n","                 return []\n","\n","        except Exception as e:\n","            logging.error(f\"An error occurred during inverse transform or label processing for {image_path}: {e}\", exc_info=True)\n","            return None"],"execution_count":64,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-30 11:42:06,061 - INFO - Logging already configured.\n"]}]},{"cell_type":"code","source":["model_path=Path(\"/content/drive/MyDrive/Work_space/Project/document_classification/artifacts/model/vgg_model/model.keras\")\n","mlb_path=Path(\"/content/drive/MyDrive/Work_space/Project/document_classification/artifacts/model/vgg_model/mlb.joblib\")\n","\n","classifier = VGGDocumentClassifier(model_path,mlb_path)\n","\n","predicted_labels = classifier.predict(Path(\"/content/38.jpg\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XlE9wmt_UuMS","executionInfo":{"status":"ok","timestamp":1751283758980,"user_tz":-330,"elapsed":3132,"user":{"displayName":"Kaushi Gihan ML","userId":"11214181140146971518"}},"outputId":"19a06261-f93a-41de-fb73-aeeea28f56fd"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-30 11:42:36,313 - INFO - Initializing VGGDocumentClassifier.\n","2025-06-30 11:42:36,325 - INFO - Starting artifact loading.\n","2025-06-30 11:42:36,328 - INFO - Attempting to load VGG model from /content/drive/MyDrive/Work_space/Project/document_classification/artifacts/model/vgg_model/model.keras\n","2025-06-30 11:42:37,908 - INFO - VGG model loaded successfully.\n","2025-06-30 11:42:37,909 - INFO - Attempting to load MultiLabelBinarizer from /content/drive/MyDrive/Work_space/Project/document_classification/artifacts/model/vgg_model/mlb.joblib\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MultiLabelBinarizer from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n","2025-06-30 11:42:37,915 - INFO - MultiLabelBinarizer loaded successfully.\n","2025-06-30 11:42:37,916 - INFO - All required VGG artifacts loaded successfully.\n","2025-06-30 11:42:37,917 - INFO - VGGDocumentClassifier initialized successfully.\n","2025-06-30 11:42:37,919 - INFO - Starting prediction process for image: /content/38.jpg.\n","2025-06-30 11:42:37,921 - INFO - Attempting to load image from /content/38.jpg\n","2025-06-30 11:42:37,927 - INFO - Image loaded successfully.\n","2025-06-30 11:42:37,927 - INFO - Attempting to convert image to RGB.\n","2025-06-30 11:42:37,930 - INFO - Image converted to RGB successfully.\n","2025-06-30 11:42:37,931 - INFO - Attempting to resize image to (224, 224).\n","2025-06-30 11:42:37,934 - INFO - Image resized successfully.\n","2025-06-30 11:42:37,934 - INFO - Attempting to normalize pixel values.\n","2025-06-30 11:42:37,936 - INFO - Pixel values normalized successfully.\n","2025-06-30 11:42:37,937 - INFO - Image preprocessing completed successfully for /content/38.jpg.\n","2025-06-30 11:42:37,938 - INFO - Performing model inference for /content/38.jpg.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-30 11:42:39,436 - INFO - Model inference completed for /content/38.jpg. Prediction shape: (1, 5)\n","2025-06-30 11:42:39,437 - INFO - Converting prediction to labels for /content/38.jpg.\n","2025-06-30 11:42:39,439 - INFO - Prediction processed for /content/38.jpg. Predicted labels (raw tuple list): [('invoice',)]\n","2025-06-30 11:42:39,440 - INFO - Final predicted labels for /content/38.jpg: ['invoice']\n"]}]},{"cell_type":"code","source":["print(predicted_labels )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5DmvrkoVZ6I","executionInfo":{"status":"ok","timestamp":1751283768737,"user_tz":-330,"elapsed":59,"user":{"displayName":"Kaushi Gihan ML","userId":"11214181140146971518"}},"outputId":"67353a73-c18a-40cd-e7f7-d26691b3ae69"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["['invoice']\n"]}]},{"cell_type":"markdown","source":["#VIT"],"metadata":{"id":"H780lemBgM0g"}},{"cell_type":"code","source":["import joblib\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from pathlib import Path\n","import torch\n","import numpy as np\n","from PIL import Image\n","from transformers import AutoImageProcessor, AutoModelForImageClassification\n","\n","\n","\n","try:\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    mlb_file_path=Path(\"artifacts\\model\\VIT_model\\mlb.joblib\")\n","    model_file_path=Path(\"artifacts\\model\\VIT_model\\model.pth\")\n","    # Select model\n","    model_id = \"google/vit-base-patch16-224-in21k\"\n","    # Load processor\n","    processor = AutoImageProcessor.from_pretrained(model_id, use_fast=True)\n","\n","    # TODO: You need to load your fine-tuned model here\n","    # For example:\n","    # model = AutoModelForImageClassification.from_pretrained(\"path/to/your/fine-tuned-model\")\n","    # For now, we will use the base model for demonstration, but it will not give correct predictions.\n","    #model = AutoModelForImageClassification.from_pretrained(model_id)\n","    # Load the entire model\n","    model= torch.load(model_file_path, map_location=device,weights_only=False )\n","    # Set device\n","    model.to(device)\n","\n","except Exception as e:\n","    raise e\n","\n","\n","\n","\n","def mlb_load(file_path:Path)->MultiLabelBinarizer:\n","    try:\n","        # Assuming you run this notebook from the root of your project directory\n","        mlb = joblib.load(file_path)\n","\n","    except FileNotFoundError:\n","        print(\"Error: 'artifacts/model/VIT_model/mlb.joblib' not found.\")\n","        print(\"Please make sure the path is correct. Using a placeholder binarizer.\")\n","        # As a placeholder, let's create a dummy mlb if the file is not found.\n","        mlb = MultiLabelBinarizer()\n","        # This should be the set of your actual labels.\n","        mlb.fit([['advertisement', 'email', 'form', 'invoice', 'note']])\n","    return mlb\n","\n","\n","\n","\n","\n","\n","def VIT_model_prediction(image_path:Path,cut_off:float):\n","    try:\n","        # Load and convert image\n","        # --- IMPORTANT: Please update this path to your image ---\n","        try:\n","            image = Image.open(image_path)\n","            if image.mode != \"RGB\":\n","                image = image.convert(\"RGB\")\n","        except FileNotFoundError:\n","            print(f\"Error: Image not found at {image_path}\")\n","            print(\"Using a dummy image for demonstration.\")\n","            # Create a dummy image for demonstration if image not found\n","            image = Image.new('RGB', (224, 224), color = 'red')\n","\n","\n","        # Preprocess image\n","        pixel_values = processor(image, return_tensors=\"pt\").pixel_values.to(device)\n","\n","        # Forward pass\n","        with torch.no_grad():\n","            outputs = model(pixel_values)\n","            logits = outputs.logits\n","\n","        # Apply sigmoid for multi-label classification\n","        sigmoid = torch.nn.Sigmoid()\n","        probs = sigmoid(logits.squeeze().cpu())\n","\n","        # Thresholding (using 0.5 as an example)\n","        predictions = np.zeros(probs.shape)\n","        predictions[np.where(probs >= cut_off)] = 1\n","\n","        # Get label names using the loaded MultiLabelBinarizer\n","        mlb=mlb_load(mlb_file_path)\n","        # The predictions need to be in a 2D array for inverse_transform, e.g., (1, num_classes)\n","        predicted_labels = mlb.inverse_transform(predictions.reshape(1, -1))\n","        print(f\"Predicted labels: {predicted_labels}\")\n","        return {\"status\":1,}\n","\n","    except Exception as e:\n","        raise e\n","\n","\n","\n","VIT_model_prediction(Path(\"dataset\\sample_text_ds\\test\\email\\2078379610a.jpg\"),0.5)"],"metadata":{"id":"onJ8e7o1pg2A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Production grade"],"metadata":{"id":"3tcNRAJcpe05"}},{"cell_type":"code","source":["import logging\n","import numpy as np\n","import torch\n","from PIL import Image\n","from transformers import AutoImageProcessor, AutoModelForImageClassification\n","from sklearn.preprocessing import MultiLabelBinarizer\n","import joblib\n","from pathlib import Path\n","from typing import List, Optional, Tuple, Any\n","\n","# Configure logging (if not already configured, set a basic configuration)\n","# Check if handlers exist to avoid adding multiple handlers in interactive environments\n","if not logging.getLogger('').handlers:\n","    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","    logging.info(\"Logging configured with basicConfig.\")\n","else:\n","    logging.info(\"Logging already configured.\")\n","\n","\n","class VITDocumentClassifier:\n","    \"\"\"\n","    A class for classifying documents using a Vision Transformer (ViT) model.\n","\n","    This class encapsulates the loading of the ViT model, its associated processor,\n","    and a MultiLabelBinarizer for converting model outputs to meaningful labels.\n","    It provides a method to preprocess input images and perform multi-label\n","    classification predictions with a specified confidence cutoff threshold.\n","    \"\"\"\n","\n","    def __init__(self, model_path: Path, mlb_path: Path, model_id: str = \"google/vit-base-patch16-224-in21k\") -> None:\n","        \"\"\"\n","        Initializes the VITDocumentClassifier by loading the model, processor, and MLB.\n","\n","        Args:\n","            model_path: Path to the ViT model file (.pth). This is expected to be\n","                        a pre-trained or fine-tuned PyTorch model file.\n","            mlb_path: Path to the MultiLabelBinarizer file (.joblib). This file\n","                      should contain the fitted binarizer object corresponding\n","                      to the model's output classes.\n","            model_id: The Hugging Face model ID for the processor. This is used\n","                      to load the appropriate image processor for the ViT model.\n","                      Defaults to \"google/vit-base-patch16-224-in21k\".\n","\n","        Raises:\n","            FileNotFoundError: If either the model file or the MLB file is not found\n","                             at the specified paths during artifact loading.\n","            Exception: If any other unexpected error occurs during the loading\n","                       of the model, processor, or MultiLabelBinarizer.\n","            RuntimeError: If artifact loading fails for critical components\n","                          (model or MLB).\n","        \"\"\"\n","        logging.info(\"Initializing VITDocumentClassifier.\")\n","        self.model: Optional[torch.nn.Module] = None\n","        self.processor: Optional[AutoImageProcessor] = None\n","        self.mlb: Optional[MultiLabelBinarizer] = None\n","        self.device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        logging.info(f\"Using device: {self.device}\")\n","        self.model_id: str = model_id\n","\n","        try:\n","            self._load_artifacts(model_path, mlb_path)\n","            if self.model and self.processor and self.mlb:\n","                logging.info(\"VITDocumentClassifier initialized successfully.\")\n","            else:\n","                # This case should ideally be caught and re-raised in _load_artifacts\n","                # but adding a check here for robustness.\n","                logging.critical(\"VITDocumentClassifier failed to fully initialize due to artifact loading errors.\")\n","                raise RuntimeError(\"Failed to load all required artifacts for VITDocumentClassifier.\")\n","\n","        except Exception as e:\n","            logging.critical(f\"Failed to initialize VITDocumentClassifier: {e}\", exc_info=True)\n","            # Re-raise the exception after logging\n","            raise\n","\n","\n","    def _load_artifacts(self, model_path: Path, mlb_path: Path) -> None:\n","        \"\"\"\n","        Loads the ViT model, processor, and MultiLabelBinarizer with enhanced error handling and logging.\n","\n","        This is an internal helper method called during initialization.\n","\n","        Args:\n","            model_path: Path to the ViT model file (.pth).\n","            mlb_path: Path to the MultiLabelBinarizer file (.joblib).\n","\n","        Raises:\n","            FileNotFoundError: If either the model file or the MLB file is not found.\n","            Exception: If any other unexpected error occurs during loading.\n","        \"\"\"\n","        logging.info(\"Starting artifact loading.\")\n","        processor_loaded: bool = False\n","        model_loaded: bool = False\n","        mlb_loaded: bool = False\n","\n","        # Load Processor\n","        try:\n","            logging.info(f\"Attempting to load ViT processor for model ID: {self.model_id}\")\n","            self.processor = AutoImageProcessor.from_pretrained(self.model_id, use_fast=True)\n","            logging.info(\"ViT processor loaded successfully.\")\n","            processor_loaded = True\n","        except Exception as e:\n","            # Log at error level as processor is important but not strictly critical if we raise later\n","            logging.error(f\"An error occurred while loading the ViT processor for model ID {self.model_id}: {e}\", exc_info=True)\n","            # Do not re-raise here, continue loading other artifacts\n","\n","\n","        # Load Model\n","        try:\n","            logging.info(f\"Attempting to load ViT model from {model_path}\")\n","            # Note: Adjust map_location as needed based on where the model was saved\n","            self.model = torch.load(model_path, map_location=self.device, weights_only=False)\n","            self.model.to(self.device) # Ensure model is on the correct device\n","            logging.info(f\"ViT model loaded successfully and moved to {self.device}.\")\n","            model_loaded = True\n","        except FileNotFoundError:\n","            logging.critical(f\"Critical Error: ViT model file not found at {model_path}\", exc_info=True)\n","            raise # Re-raise to indicate a critical initialization failure\n","        except Exception as e:\n","            logging.critical(f\"Critical Error: An unexpected error occurred while loading the ViT model from {model_path}: {e}\", exc_info=True)\n","            raise # Re-raise to indicate a critical initialization failure\n","\n","\n","        # Load MLB\n","        try:\n","            logging.info(f\"Attempting to load MultiLabelBinarizer from {mlb_path}\")\n","            self.mlb = joblib.load(mlb_path)\n","            logging.info(\"MultiLabelBinarizer loaded successfully.\")\n","            mlb_loaded = True\n","        except FileNotFoundError:\n","            logging.critical(f\"Critical Error: MultiLabelBinarizer file not found at {mlb_path}\", exc_info=True)\n","            raise # Re-raise to indicate a critical initialization failure\n","        except Exception as e:\n","            logging.critical(f\"Critical Error: An unexpected error occurred while loading the MultiLabelBinarizer from {mlb_path}: {e}\", exc_info=True)\n","            raise # Re-raise to indicate a critical initialization failure\n","\n","        if processor_loaded and model_loaded and mlb_loaded:\n","             logging.info(\"All required ViT artifacts loaded successfully.\")\n","        else:\n","            logging.error(\"One or more required ViT artifacts failed to load during _load_artifacts.\")\n","\n","\n","    def predict(self, image_path: Path, cut_off: float = 0.5) -> Optional[List[str]]:\n","        \"\"\"\n","        Predicts the class labels for a given image using the loaded ViT model.\n","\n","        The process involves loading and preprocessing the image, performing\n","        inference with the model, applying a sigmoid activation, thresholding\n","        the probabilities to obtain binary predictions, and finally converting\n","        the binary predictions back to class labels using the MultiLabelBinarizer.\n","\n","        Args:\n","            image_path: Path to the image file to classify. The image is expected\n","                        to be in a format compatible with PIL (Pillow).\n","            cut_off: The threshold for converting predicted probabilities into\n","                     binary labels. Probabilities greater than or equal to this\n","                     value are considered positive predictions (1), otherwise 0.\n","                     Defaults to 0.5.\n","\n","        Returns:\n","            A list of predicted class labels (strings) if the prediction process\n","            is successful. Returns None if any critical step (image loading,\n","            preprocessing, model inference, or inverse transform) fails.\n","            Returns an empty list if the prediction process is successful but\n","            no labels meet the cutoff threshold.\n","        \"\"\"\n","        logging.info(f\"Starting prediction process for image: {image_path} with cutoff {cut_off}.\")\n","\n","        if self.model is None or self.processor is None or self.mlb is None:\n","            logging.error(\"Model, processor, or MultiLabelBinarizer not loaded. Cannot perform prediction.\")\n","            return None\n","\n","        # Load and preprocess image\n","        image: Optional[Image.Image] = None\n","        try:\n","            logging.info(f\"Attempting to load image from {image_path}\")\n","            image = Image.open(image_path)\n","            logging.info(f\"Image loaded successfully from {image_path}.\")\n","        except FileNotFoundError:\n","            logging.error(f\"Error: Image file not found at {image_path}\", exc_info=True)\n","            return None\n","        except Exception as e:\n","            logging.error(f\"An unexpected error occurred while loading image {image_path}: {e}\", exc_info=True)\n","            return None\n","\n","        try:\n","            logging.info(f\"Attempting to convert image to RGB for {image_path}.\")\n","            if image.mode != \"RGB\":\n","                image = image.convert(\"RGB\")\n","                logging.info(f\"Image converted to RGB successfully for {image_path}.\")\n","            else:\n","                 logging.info(f\"Image is already in RGB format for {image_path}.\")\n","\n","        except Exception as e:\n","            logging.error(f\"An error occurred while converting image {image_path} to RGB: {e}\", exc_info=True)\n","            return None\n","\n","\n","        # Preprocess image using the loaded processor\n","        try:\n","            logging.info(f\"Attempting to preprocess image using processor for {image_path}.\")\n","            # Check if image is valid after loading/conversion\n","            if image is None:\n","                 logging.error(f\"Image is None after loading/conversion for {image_path}. Cannot preprocess.\")\n","                 return None\n","            # The processor expects a PIL Image or a list of PIL Images\n","            pixel_values: torch.Tensor = self.processor(images=image, return_tensors=\"pt\").pixel_values.to(self.device)\n","            logging.info(f\"Image preprocessed and moved to device ({self.device}).\")\n","        except Exception as e:\n","            logging.error(f\"An error occurred during image preprocessing for {image_path}: {e}\", exc_info=True)\n","            return None\n","\n","        # Forward pass\n","        try:\n","            logging.info(f\"Starting model forward pass for {image_path}.\")\n","            self.model.eval() # Set model to evaluation mode\n","            with torch.no_grad():\n","                outputs: Any = self.model(pixel_values) # Use Any because the output type can vary\n","                logits: torch.Tensor = outputs.logits\n","            logging.info(f\"Model forward pass completed for {image_path}.\")\n","        except Exception as e:\n","            logging.error(f\"An error occurred during model forward pass for {image_path}: {e}\", exc_info=True)\n","            return None\n","\n","\n","        # Apply sigmoid and thresholding\n","        try:\n","            logging.info(f\"Applying sigmoid and thresholding for {image_path}.\")\n","            sigmoid: torch.nn.Sigmoid = torch.nn.Sigmoid()\n","            probs: torch.Tensor = sigmoid(logits.squeeze().cpu())\n","\n","            predictions: np.ndarray = np.zeros(probs.shape, dtype=int) # Explicitly set dtype to int\n","            predictions[np.where(probs >= cut_off)] = 1\n","            logging.info(f\"Applied sigmoid and thresholding with cutoff {cut_off} for {image_path}. Binary predictions shape: {predictions.shape}\")\n","        except Exception as e:\n","            logging.error(f\"An error occurred during probability processing for {image_path}: {e}\", exc_info=True)\n","            return None\n","\n","\n","        # Get label names using the loaded MultiLabelBinarizer\n","        try:\n","            logging.info(f\"Performing inverse transform using MultiLabelBinarizer for {image_path}.\")\n","            # The predictions need to be in a 2D array for inverse_transform, e.g., (1, num_classes)\n","            # Use the self.mlb loaded during initialization\n","\n","            # Ensure self.mlb is not None (checked at the start of predict, but good practice)\n","            if self.mlb is None:\n","                 logging.error(f\"MultiLabelBinarizer is None. Cannot perform inverse transform for {image_path}.\")\n","                 return None\n","\n","            binary_prediction: np.ndarray\n","\n","            # Ensure predictions shape is compatible (must be 2D: (n_samples, n_classes))\n","            # Since we process one image at a time, expected shape is (1, n_classes)\n","            expected_shape: Tuple[int, int] = (1, len(self.mlb.classes_))\n","\n","            if predictions.ndim == 1 and predictions.shape[0] == len(self.mlb.classes_):\n","                 binary_prediction = predictions.reshape(expected_shape)\n","                 logging.info(f\"Reshaped 1D prediction to 2D ({expected_shape}) for inverse transform.\")\n","            elif predictions.ndim == 2 and predictions.shape == expected_shape:\n","                 binary_prediction = predictions\n","                 logging.info(f\"Prediction already in correct 2D shape ({expected_shape}) for inverse transform.\")\n","            else:\n","                 logging.error(f\"Cannot inverse transform prediction shape {predictions.shape} with MLB classes {len(self.mlb.classes_)} for {image_path}. Expected shape: {expected_shape}\")\n","                 return None\n","\n","\n","            predicted_labels_tuple_list: List[Tuple[str, ...]] = self.mlb.inverse_transform(binary_prediction)\n","            logging.info(f\"Prediction processed for {image_path}. Predicted labels (raw tuple list): {predicted_labels_tuple_list}\")\n","\n","            # inverse_transform returns a list of tuples, even for a single sample.\n","            # We expect a single prediction here, so we take the first tuple.\n","            if predicted_labels_tuple_list and len(predicted_labels_tuple_list) > 0:\n","                final_labels: List[str] = list(predicted_labels_tuple_list[0])\n","                logging.info(f\"Final predicted labels for {image_path}: {final_labels}\")\n","                return final_labels\n","            else:\n","                 logging.warning(f\"MLB inverse_transform returned an empty list for {image_path}. No labels predicted.\")\n","                 return []\n","\n","\n","        except Exception as e:\n","            logging.error(f\"An error occurred during inverse transform for {image_path}: {e}\", exc_info=True)\n","            return None"],"metadata":{"id":"4W0N4s-HorZZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LayoutLM"],"metadata":{"id":"hrMyf9b0vOB7"}},{"cell_type":"code","source":["\n","from PIL import Image, ImageDraw, ImageFont\n","from transformers import LayoutLMv2ForSequenceClassification\n","from PIL import Image\n","import numpy as np\n","import torch\n","from typing import Optional, List, Dict, Any\n","import logging\n","from pathlib import Path\n","from transformers import LayoutLMv2ForSequenceClassification, LayoutLMv2Processor, LayoutLMv2FeatureExtractor, LayoutLMv2Tokenizer\n","import os\n","from dotenv import load_dotenv\n","\n","try:\n","    load_model = LayoutLMv2ForSequenceClassification.from_pretrained(\"/kaggle/working/model.pth\")\n","    model.to(device)\n","except Exception as e:\n","    raise e\n","\n","def layout_model_prediction(img_path):\n","\n","\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","    id2label={0:'invoice',1: 'form', 2:'note', 3:'advertisement',4: 'email'}\n","    image = Image.open(img_path)\n","    image = image.convert(\"RGB\")\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    # prepare image for the model\n","    encoded_inputs = processor(\n","    image,\n","    return_tensors=\"pt\",\n","    truncation=True,\n","    padding=\"max_length\",\n","    max_length=512)\n","\n","    # make sure all keys of encoded_inputs are on the same device as the model\n","    for k,v in encoded_inputs.items():\n","      encoded_inputs[k] = v.to(model.device)\n","\n","    load_model.to(device)\n","    # forward pass\n","    outputs = load_model(**encoded_inputs)\n","    logits = outputs.logits\n","\n","    predicted_class_idx = logits.argmax(-1).item()\n","    print(\"Predicted class:\", id2label[predicted_class_idx])\n","\n","    return id2label[predicted_class_idx]"],"metadata":{"id":"gdGZRdvevTaX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Production grade"],"metadata":{"id":"at9IoWOG20uS"}},{"cell_type":"code","metadata":{"id":"38156374","executionInfo":{"status":"ok","timestamp":1751302864791,"user_tz":-330,"elapsed":85,"user":{"displayName":"Kaushi Gihan ML","userId":"11214181140146971518"}}},"source":["from PIL import Image\n","import numpy as np\n","import torch\n","from typing import Optional, List, Dict, Any\n","import logging\n","from pathlib import Path\n","from transformers import LayoutLMv2ForSequenceClassification, LayoutLMv2Processor, LayoutLMv2FeatureExtractor, LayoutLMv2Tokenizer\n","import os\n","from dotenv import load_dotenv\n","\n","# Configure logging (if not already configured)\n","# Check if handlers exist to avoid adding multiple handlers in interactive environments\n","if not logging.getLogger('').handlers:\n","    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","    logging.info(\"Logging configured with basicConfig.\")\n","else:\n","    logging.info(\"Logging already configured.\")\n","\n","# Load environment variables from .env file\n","# Set override=True to allow overriding existing environment variables\n","load_dotenv(override=True)\n","\n","class LayoutLMDocumentClassifier:\n","    \"\"\"\n","    A class for classifying documents using a LayoutLMv2 model.\n","\n","    This class encapsulates the loading of the LayoutLMv2 model and its associated\n","    processor, handles image preprocessing, and performs document classification\n","    predictions. The model path is loaded from environment variables, promoting\n","    flexible configuration. It includes robust error handling, logging, and\n","    type hinting for production readiness.\n","    \"\"\"\n","\n","    def __init__(self,model_path_str) -> None:\n","        \"\"\"\n","        Initializes the LayoutLMDocumentClassifier by loading the model and processor.\n","\n","        The model and processor are loaded from the path specified in the\n","        environment variable 'LAYOUTLM_MODEL_PATH'. This method also sets up\n","        the device for inference (GPU if available, otherwise CPU) and defines\n","         the mapping from model output indices to class labels.\n","\n","        Includes robust error handling and logging for initialization and artifact loading.\n","\n","        Raises:\n","            ValueError: If the 'LAYOUTLM_MODEL_PATH' environment variable is not set.\n","            FileNotFoundError: If the model path specified in the environment variable\n","                               does not exist or a required artifact file is not found\n","                               during the artifact loading process.\n","            Exception: If any other unexpected error occurs during the loading\n","                       of the model or processor.\n","        \"\"\"\n","        logging.info(\"Initializing LayoutLMDocumentClassifier.\")\n","        self.model_path_str: Optional[str]=model_path_str\n","        self.model: Optional[LayoutLMv2ForSequenceClassification] = None\n","        self.processor: Optional[LayoutLMv2Processor] = None\n","        self.device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        logging.info(f\"Using device: {self.device}\")\n","        # Define id2label mapping as a class attribute\n","        # This mapping should align with the model's output classes.\n","        self.id2label: Dict[int, str] = {0:'invoice', 1: 'form', 2:'note', 3:'advertisement', 4: 'email'}\n","        logging.info(f\"Defined id2label mapping: {self.id2label}\")\n","\n","        # Load model path from environment variable\n","        model_path_str: Optional[str] = self.model_path_str\n","        logging.info(f\"Attempting to retrieve LAYOUTLM_MODEL_PATH from environment variables.\")\n","        if not model_path_str:\n","            logging.critical(\"Critical Error: 'LAYOUTLM_MODEL_PATH' environment variable is not set.\")\n","            raise ValueError(\"LAYOUTLM_MODEL_PATH environment variable is not set.\")\n","\n","        model_path: Path = Path(model_path_str)\n","        logging.info(f\"Retrieved model path: {model_path}\")\n","        if not model_path.exists():\n","             logging.critical(f\"Critical Error: Model path from environment variable does not exist: {model_path}\")\n","             raise FileNotFoundError(f\"Model path not found: {model_path}\")\n","        logging.info(f\"Model path {model_path} exists.\")\n","\n","\n","        try:\n","            logging.info(\"Calling _load_artifacts to load model and processor.\")\n","            self._load_artifacts(model_path)\n","            if self.model is not None and self.processor is not None:\n","                logging.info(\"LayoutLMDocumentClassifier initialized successfully.\")\n","            else:\n","                # This case should ideally be caught and re-raised in _load_artifacts\n","                logging.critical(\"LayoutLMDocumentClassifier failed to fully initialize due to artifact loading errors in _load_artifacts.\")\n","                # _load_artifacts already raises on critical failure, no need to raise again\n","        except Exception as e:\n","            # Catch and log any exception that wasn't handled and re-raised in _load_artifacts\n","            logging.critical(f\"An unhandled exception occurred during LayoutLMDocumentClassifier initialization: {e}\", exc_info=True)\n","            raise # Re-raise the exception after logging\n","        logging.info(\"Initialization process completed.\")\n","\n","\n","    def _load_artifacts(self, model_path: Path) -> None:\n","        \"\"\"\n","        Loads the LayoutLMv2 model and processor from the specified path.\n","\n","        This is an internal helper method called during initialization. It handles\n","        the loading of both the `LayoutLMv2ForSequenceClassification` model and\n","        its corresponding `LayoutLMv2Processor` with error handling and logging.\n","\n","        Args:\n","            model_path: Path to the LayoutLMv2 model directory or file. This path\n","                        is expected to contain both the model weights and the\n","                        processor configuration/files.\n","\n","        Raises:\n","            FileNotFoundError: If the `model_path` or any required processor/model\n","                               file within that path is not found.\n","            Exception: If any other unexpected error occurs during loading\n","                       from the specified path (e.g., corrupt files, compatibility issues).\n","        \"\"\"\n","        logging.info(f\"Starting artifact loading from {model_path} for LayoutLMv2.\")\n","        processor_loaded: bool = False\n","        model_loaded: bool = False\n","\n","        # Load Processor\n","        try:\n","            logging.info(f\"Attempting to load LayoutLMv2 processor from {model_path}\")\n","            # Load feature extractor and tokenizer separately to create the processor\n","            feature_extractor = LayoutLMv2FeatureExtractor()\n","            tokenizer = LayoutLMv2Tokenizer.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n","            self.processor = LayoutLMv2Processor(feature_extractor, tokenizer)\n","            logging.info(\"LayoutLMv2 processor loaded successfully.\")\n","            processor_loaded = True\n","        except Exception as e:\n","            logging.critical(f\"Critical Error: An unexpected error occurred while loading the LayoutLMv2 processor from {model_path}: {e}\", exc_info=True)\n","            raise # Re-raise to indicate a critical initialization failure\n","\n","        # Load Model\n","        try:\n","            logging.info(f\"Attempting to load LayoutLMv2 model from {model_path}\")\n","            self.model = LayoutLMv2ForSequenceClassification.from_pretrained(model_path)\n","            self.model.to(self.device) # Ensure model is on the correct device\n","            logging.info(f\"LayoutLMv2 model loaded successfully and moved to {self.device}.\")\n","            model_loaded = True\n","        except FileNotFoundError:\n","            logging.critical(f\"Critical Error: LayoutLMv2 model file not found at {model_path}\", exc_info=True)\n","            raise # Re-raise to indicate a critical initialization failure\n","        except Exception as e:\n","            logging.critical(f\"Critical Error: An unexpected error occurred while loading the LayoutLMv2 model from {model_path}: {e}\", exc_info=True)\n","            raise # Re-raise to indicate a critical initialization failure\n","\n","        # Conditional logging based on loading success\n","        if model_loaded and processor_loaded:\n","             logging.info(\"All required LayoutLMv2 artifacts loaded successfully from _load_artifacts.\")\n","        elif model_loaded and not processor_loaded:\n","             logging.error(\"LayoutLMv2 model loaded successfully, but processor loading failed in _load_artifacts.\")\n","        elif not model_loaded and processor_loaded:\n","             logging.error(\"LayoutLMv2 processor loaded successfully, but model loading failed in _load_artifacts.\")\n","        else:\n","            logging.error(\"Both LayoutLMv2 model and processor failed to load during _load_artifacts.\")\n","        logging.info(\"Artifact loading process completed.\")\n","\n","\n","    def _prepare_inputs(self, image_path: Path) -> Optional[Dict[str, torch.Tensor]]:\n","        \"\"\"\n","        Loads and preprocesses an image to prepare inputs for the LayoutLMv2 model.\n","\n","        This method handles loading the image from a file path, converting it to RGB,\n","        and using the loaded LayoutLMv2Processor to create the necessary input tensors\n","        (pixel values, input IDs, attention masks, bounding boxes). The tensors are\n","        then moved to the appropriate device for inference.\n","\n","        Includes robust error handling and logging for each step.\n","\n","        Args:\n","            image_path: Path to the image file (e.g., PNG, JPG) to be processed.\n","\n","        Returns:\n","            A dictionary containing the prepared input tensors (e.g., 'pixel_values',\n","            'input_ids', 'attention_mask', 'bbox') as PyTorch tensors, if image\n","            loading and preprocessing are successful. Returns `None` if any\n","            step fails (e.g., file not found, image corruption, processor error).\n","        \"\"\"\n","        logging.info(f\"Starting image loading and preprocessing for {image_path}.\")\n","        image: Optional[Image.Image] = None\n","\n","        # Load image\n","        try:\n","            logging.info(f\"Attempting to load image from {image_path}\")\n","            image = Image.open(image_path)\n","            logging.info(f\"Image loaded successfully from {image_path}.\")\n","        except FileNotFoundError:\n","            logging.error(f\"Error: Image file not found at {image_path}\", exc_info=True)\n","            return None\n","        except Exception as e:\n","            logging.error(f\"An unexpected error occurred while loading image {image_path}: {e}\", exc_info=True)\n","            return None\n","\n","        # Convert image to RGB\n","        try:\n","            logging.info(f\"Attempting to convert image to RGB for {image_path}.\")\n","            if image is None:\n","                 logging.error(f\"Image is None after loading for {image_path}. Cannot convert to RGB.\")\n","                 return None\n","            if image.mode != \"RGB\":\n","                image = image.convert(\"RGB\")\n","                logging.info(f\"Image converted to RGB successfully for {image_path}.\")\n","            else:\n","                 logging.info(f\"Image is already in RGB format for {image_path}.\")\n","\n","        except Exception as e:\n","            logging.error(f\"An error occurred while converting image {image_path} to RGB: {e}\", exc_info=True)\n","            return None\n","\n","\n","        # Prepare inputs using the processor\n","        if self.processor is None:\n","            logging.error(\"LayoutLMv2 processor is not loaded. Cannot prepare inputs.\")\n","            return None\n","\n","        encoded_inputs: Optional[Dict[str, torch.Tensor]] = None\n","        try:\n","            logging.info(f\"Attempting to prepare inputs using processor for {image_path}.\")\n","            # The processor expects a PIL Image or a list of PIL Images\n","            if image is None:\n","                 logging.error(f\"Image is None before preprocessing for {image_path}. Cannot prepare inputs.\")\n","                 return None\n","\n","            encoded_inputs = self.processor(\n","                images=image,\n","                return_tensors=\"pt\",\n","                truncation=True,\n","                padding=\"max_length\",\n","                max_length=512\n","            )\n","            logging.info(f\"Inputs prepared successfully for {image_path}.\")\n","        except Exception as e:\n","            logging.error(f\"An error occurred during input preparation for {image_path}: {e}\", exc_info=True)\n","            return None\n","\n","        # Move inputs to the device\n","        if encoded_inputs is not None:\n","            try:\n","                logging.info(f\"Attempting to move inputs to device ({self.device}) for {image_path}.\")\n","                for k, v in encoded_inputs.items():\n","                    if isinstance(v, torch.Tensor):\n","                        encoded_inputs[k] = v.to(self.device)\n","                logging.info(f\"Inputs moved to device ({self.device}) successfully for {image_path}.\")\n","            except Exception as e:\n","                logging.error(f\"An error occurred while moving inputs to device for {image_path}: {e}\", exc_info=True)\n","                return None\n","        else:\n","             logging.error(f\"Encoded inputs are None after processing for {image_path}. Cannot move to device.\")\n","             return None\n","\n","\n","        logging.info(f\"Image loading and preprocessing completed successfully for {image_path}.\")\n","        return encoded_inputs\n","\n","\n","    def predict(self, image_path: Path) -> Optional[str]:\n","        \"\"\"\n","        Predicts the class label for a given image using the loaded LayoutLMv2 model.\n","\n","        This is the main prediction method. It orchestrates the process by first\n","        preparing the image inputs using `_prepare_inputs`, performing inference\n","        with the LayoutLMv2 model, determining the predicted class index from the\n","        model's output logits, and finally mapping this index to a human-readable\n","        class label using the `id2label` mapping.\n","\n","        Includes robust error handling and logging throughout the prediction pipeline.\n","\n","        Args:\n","            image_path: Path to the image file to classify.\n","\n","        Returns:\n","            The predicted class label as a string if the entire prediction process\n","            is successful. Returns `None` if any critical step fails (e.g.,\n","            image loading/preprocessing, model inference, or if the predicted\n","            index is not found in the `id2label` mapping).\n","        \"\"\"\n","        logging.info(f\"Starting prediction process for image: {image_path}.\")\n","\n","        # Prepare inputs\n","        logging.info(f\"Calling _prepare_inputs for {image_path}.\")\n","        encoded_inputs: Optional[Dict[str, torch.Tensor]] = self._prepare_inputs(image_path)\n","        if encoded_inputs is None:\n","            logging.error(f\"Input preparation failed for {image_path}. Cannot perform prediction.\")\n","            logging.info(f\"Prediction process failed for {image_path}.\")\n","            return None\n","        logging.info(f\"Input preparation successful for {image_path}.\")\n","\n","\n","        # Check if model is loaded\n","        if self.model is None:\n","            logging.error(\"LayoutLMv2 model is not loaded. Cannot perform prediction.\")\n","            logging.info(f\"Prediction process failed for {image_path}.\")\n","            return None\n","        logging.info(\"LayoutLMv2 model is loaded. Proceeding with inference.\")\n","\n","        predicted_label: Optional[str] = None\n","\n","        try:\n","            logging.info(f\"Performing model inference for {image_path}.\")\n","            self.model.eval() # Set model to evaluation mode\n","            with torch.no_grad():\n","                outputs: Any = self.model(**encoded_inputs)\n","                logits: torch.Tensor = outputs.logits\n","\n","            # Determine predicted class index\n","            # Ensure logits is a tensor before calling argmax\n","            if not isinstance(logits, torch.Tensor):\n","                 logging.error(f\"Model output 'logits' is not a torch.Tensor for {image_path}. Cannot determine predicted index.\")\n","                 logging.info(f\"Prediction process failed for {image_path} due to invalid model output.\")\n","                 return None\n","\n","            predicted_class_idx: int = logits.argmax(-1).item()\n","            logging.info(f\"Model inference completed for {image_path}. Predicted index: {predicted_class_idx}.\")\n","\n","            # Map index to label\n","            logging.info(f\"Attempting to map predicted index {predicted_class_idx} to label.\")\n","            if predicted_class_idx in self.id2label:\n","                predicted_label = self.id2label[predicted_class_idx]\n","                logging.info(f\"Mapped predicted index {predicted_class_idx} to label: {predicted_label}.\")\n","            else:\n","                logging.error(f\"Predicted index {predicted_class_idx} not found in id2label mapping for {image_path}.\")\n","                logging.info(f\"Prediction process failed for {image_path} due to unknown predicted index.\")\n","                return None # Return None if index is not in mapping\n","\n","        except Exception as e:\n","            logging.error(f\"An error occurred during model inference or label mapping for {image_path}: {e}\", exc_info=True)\n","            logging.info(f\"Prediction process failed for {image_path} due to inference/mapping error.\")\n","            return None\n","\n","        logging.info(f\"Prediction process completed successfully for {image_path}. Predicted label: {predicted_label}.\")\n","        return predicted_label"],"execution_count":9,"outputs":[]}]}